## AR-VAE: Attribute-based Regularization of VAE Latent Spaces

### Introduction 
Selective manipulation of data attributes using deep generative models is an active area of research in the machine learning community. Latent representation-based models such as Variational Auto-Encoders (VAEs) show promise in this direction as they can encode hidden attributes of data. The goal of this research work is to make these latent spaces more **interpretable** by encoding **semantically meaningful attributes** along **specific dimensions** of the latent space. 

**AR-VAE** is a type of Variational Auto-Encoder (VAE) which uses a new supervised training method to create structured latent spaces where specific continuous-valued attributes are forced to be encoded along specific dimensions of the latent space. The figure below shows the main idea behind the AR-VAE model.

<p align="center">
    <img src=../figs/motivation_arvae.svg width=700px><br>
</p>

The goal is to structure the latent space such that if the attribute value `a` of one data-point `i` is greater than that of data-point `j`, the latent code correponding to the regularized dimension `r` should also be greater for `i`. This is accomplished by adding a **attribute regularization loss** to the standard VAE-objective using the following steps. See our [paper](https://arxiv.org/pdf/2004.05485.pdf) for more details regarding the method.


### Experimental Results
We compare the performance of our model against the [beta-VAE](https://pdfs.semanticscholar.org/a902/26c41b79f8b06007609f39f82757073641e2.pdf) model using datasets from both image and music domains using a wide range of quantitative and qualitative evalution methods. 

1. **Manipulation of Attributes**

Manipulating attributes of 2-d shapes. Each row in the figure below represents a unique shape (from top to bottom): <i>square, heart, ellipse</i>. Each column corresponds to traversal along a regularized dimension which encodes a specific attribute (from left to right): *Shape, Scale, Orientation, x-position, y-position*.
<p align="center">
    <img src=../figs/gif_interpolations_dsprites_0.gif><br>
    <img src=../figs/gif_interpolations_dsprites_1.gif><br>
    <img src=../figs/gif_interpolations_dsprites_4.gif><br>
   
</p>


Manipulating attributes of MNIST digits. Each row in the figure below represents a unique digit fronm 0 to 9. Each column corresponds to traversal along a regularized dimension which encodes a specific attribute (from left to right): *Area, Length, Thickness, Slant, Width, Height*.
<p align="center">
    <img src=../figs/gif_interpolations_mnist_28.gif><br>
    <img src=../figs/gif_interpolations_mnist_5.gif><br>
    <img src=../figs/gif_interpolations_mnist_1.gif><br>
    <img src=../figs/gif_interpolations_mnist_30.gif><br>
    <img src=../figs/gif_interpolations_mnist_19.gif><br>
    <img src=../figs/gif_interpolations_mnist_23.gif><br>
    <img src=../figs/gif_interpolations_mnist_21.gif><br>
    <img src=../figs/gif_interpolations_mnist_17.gif><br>
    <img src=../figs/gif_interpolations_mnist_61.gif><br>
    <img src=../figs/gif_interpolations_mnist_9.gif><br>
</p>

Manipulating attributes of monophonic measures of music. In the figure below, measures on each staff line are generated by traversal along a regularized dimension which encodes a specific musical attribute (shown on the extreme left).
<p align="center">
    <img src=../figs/interp_score_15_11.svg><br>
</p>

Piano roll version of the figure above is shown below. Plots on the right of each pianoroll show the progression of attribute values.
<p align="center">
    <img src=../figs/interp_pianoroll_15_11.svg><br>
</p>   

In comparison, the baseline beta-VAE often either fails to encode specific attribute properly or fails to retain the content of the original data (see the right column in the figure below). 
<p align="center">
    <img src=../figs/interp_dsprites.png width="600"><br>
</p> 
<p align="center">
    <img src=../figs/interp_mnist.png width="600"><br>
</p> 



2. **Latent Space Disentanglement**

Disentanglement of latent spaces is evaluated using several objective metrics (higher is better). The box plots below show the results for all the four datsets considered. AR-VAE scores better than the baseline across different metrics. 

<p float="center">
  <img src="../figs/evaluation_Interpretability.png" width="250" />
  <img src="../figs/evaluation_MIG.png" width="250" /> 
  <img src="../figs/evaluation_SAP.png" width="250" />
</p>

3. **Reconstruction Fidelity**

The figure below shows examples of reconstruction in the image-based datasets. The AR-VAE model has sharper reconstructions compared to the beta-VAE model.

<p align="center">
    <img src=../figs/recons_examples.png width="400"><br>
</p>  


### Additional Information
For more information on how use the code in this repository, please see readme of [this](https://github.com/ashispati/ar-vae) repository. For more details regarding the model configurations, experiments, and additional results, please refer our [paper](https://arxiv.org/pdf/2004.05485.pdf).
